{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>의료기관</th>\n",
       "      <th>전입인구</th>\n",
       "      <th>전출인구</th>\n",
       "      <th>자가용</th>\n",
       "      <th>65세이상인구</th>\n",
       "      <th>재정자립도</th>\n",
       "      <th>지수</th>\n",
       "      <th>변동</th>\n",
       "      <th>유치원</th>\n",
       "      <th>선행종합지수</th>\n",
       "      <th>...</th>\n",
       "      <th>랜드마크_김포공항</th>\n",
       "      <th>랜드마크_남산타워</th>\n",
       "      <th>랜드마크_롯데월드</th>\n",
       "      <th>랜드마크_서울월드컵경기장</th>\n",
       "      <th>랜드마크_야구장</th>\n",
       "      <th>랜드마크_없음</th>\n",
       "      <th>랜드마크_잠실야구장</th>\n",
       "      <th>랜드마크_코엑스</th>\n",
       "      <th>랜드마크_한강공원</th>\n",
       "      <th>상하강률</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1259.0</td>\n",
       "      <td>32482.0</td>\n",
       "      <td>11209.7</td>\n",
       "      <td>202145.8</td>\n",
       "      <td>50327.0</td>\n",
       "      <td>73.9</td>\n",
       "      <td>95.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>47.0</td>\n",
       "      <td>82.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1269.0</td>\n",
       "      <td>27486.0</td>\n",
       "      <td>9968.7</td>\n",
       "      <td>202468.3</td>\n",
       "      <td>50911.0</td>\n",
       "      <td>73.9</td>\n",
       "      <td>95.5</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>47.0</td>\n",
       "      <td>83.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1279.0</td>\n",
       "      <td>25307.0</td>\n",
       "      <td>9110.7</td>\n",
       "      <td>202906.0</td>\n",
       "      <td>51465.0</td>\n",
       "      <td>73.9</td>\n",
       "      <td>94.2</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>47.0</td>\n",
       "      <td>83.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1268.0</td>\n",
       "      <td>32145.0</td>\n",
       "      <td>11939.7</td>\n",
       "      <td>202899.5</td>\n",
       "      <td>52925.0</td>\n",
       "      <td>73.9</td>\n",
       "      <td>93.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1274.0</td>\n",
       "      <td>35972.0</td>\n",
       "      <td>12526.0</td>\n",
       "      <td>203646.5</td>\n",
       "      <td>53386.7</td>\n",
       "      <td>61.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>48.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 460 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     의료기관     전입인구     전출인구       자가용  65세이상인구  재정자립도    지수   변동   유치원  \\\n",
       "0  1259.0  32482.0  11209.7  202145.8  50327.0   73.9  95.7  0.3  47.0   \n",
       "1  1269.0  27486.0   9968.7  202468.3  50911.0   73.9  95.5 -0.3  47.0   \n",
       "2  1279.0  25307.0   9110.7  202906.0  51465.0   73.9  94.2 -0.5  47.0   \n",
       "3  1268.0  32145.0  11939.7  202899.5  52925.0   73.9  93.5  0.0  47.0   \n",
       "4  1274.0  35972.0  12526.0  203646.5  53386.7   61.2  94.3  0.3  48.0   \n",
       "\n",
       "   선행종합지수  ...  랜드마크_김포공항  랜드마크_남산타워  랜드마크_롯데월드  랜드마크_서울월드컵경기장  랜드마크_야구장  \\\n",
       "0    82.8  ...          0          0          0              0         0   \n",
       "1    83.2  ...          0          0          0              0         0   \n",
       "2    83.8  ...          0          0          0              0         0   \n",
       "3    84.0  ...          0          0          0              0         0   \n",
       "4    85.0  ...          0          0          0              0         0   \n",
       "\n",
       "   랜드마크_없음  랜드마크_잠실야구장  랜드마크_코엑스  랜드마크_한강공원   상하강률  \n",
       "0        1           0         0          0  0.000  \n",
       "1        1           0         0          0  0.060  \n",
       "2        1           0         0          0 -0.047  \n",
       "3        1           0         0          0  0.002  \n",
       "4        1           0         0          0  0.049  \n",
       "\n",
       "[5 rows x 460 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('머신러닝data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>의료기관</th>\n",
       "      <th>전입인구</th>\n",
       "      <th>전출인구</th>\n",
       "      <th>자가용</th>\n",
       "      <th>65세이상인구</th>\n",
       "      <th>재정자립도</th>\n",
       "      <th>지수</th>\n",
       "      <th>변동</th>\n",
       "      <th>유치원</th>\n",
       "      <th>선행종합지수</th>\n",
       "      <th>...</th>\n",
       "      <th>랜드마크_김포공항</th>\n",
       "      <th>랜드마크_남산타워</th>\n",
       "      <th>랜드마크_롯데월드</th>\n",
       "      <th>랜드마크_서울월드컵경기장</th>\n",
       "      <th>랜드마크_야구장</th>\n",
       "      <th>랜드마크_없음</th>\n",
       "      <th>랜드마크_잠실야구장</th>\n",
       "      <th>랜드마크_코엑스</th>\n",
       "      <th>랜드마크_한강공원</th>\n",
       "      <th>상하강률</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.061995</td>\n",
       "      <td>3.233677</td>\n",
       "      <td>1.072803</td>\n",
       "      <td>20.468395</td>\n",
       "      <td>5.046401</td>\n",
       "      <td>-0.058389</td>\n",
       "      <td>-0.056174</td>\n",
       "      <td>-0.065865</td>\n",
       "      <td>-0.061121</td>\n",
       "      <td>-0.057485</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.065896</td>\n",
       "      <td>-0.065896</td>\n",
       "      <td>-0.065896</td>\n",
       "      <td>-0.065896</td>\n",
       "      <td>-0.065896</td>\n",
       "      <td>-0.065794</td>\n",
       "      <td>-0.065896</td>\n",
       "      <td>-0.065896</td>\n",
       "      <td>-0.065896</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.064283</td>\n",
       "      <td>2.731338</td>\n",
       "      <td>0.949303</td>\n",
       "      <td>20.532285</td>\n",
       "      <td>5.114363</td>\n",
       "      <td>-0.057295</td>\n",
       "      <td>-0.055097</td>\n",
       "      <td>-0.064843</td>\n",
       "      <td>-0.060031</td>\n",
       "      <td>-0.056349</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.064813</td>\n",
       "      <td>-0.064813</td>\n",
       "      <td>-0.064813</td>\n",
       "      <td>-0.064813</td>\n",
       "      <td>-0.064813</td>\n",
       "      <td>-0.064711</td>\n",
       "      <td>-0.064813</td>\n",
       "      <td>-0.064813</td>\n",
       "      <td>-0.064813</td>\n",
       "      <td>0.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.065673</td>\n",
       "      <td>2.507137</td>\n",
       "      <td>0.861445</td>\n",
       "      <td>20.552815</td>\n",
       "      <td>5.165028</td>\n",
       "      <td>-0.056776</td>\n",
       "      <td>-0.054713</td>\n",
       "      <td>-0.064336</td>\n",
       "      <td>-0.059509</td>\n",
       "      <td>-0.055770</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.064285</td>\n",
       "      <td>-0.064285</td>\n",
       "      <td>-0.064285</td>\n",
       "      <td>-0.064285</td>\n",
       "      <td>-0.064285</td>\n",
       "      <td>-0.064183</td>\n",
       "      <td>-0.064285</td>\n",
       "      <td>-0.064285</td>\n",
       "      <td>-0.064285</td>\n",
       "      <td>-0.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.061689</td>\n",
       "      <td>3.178491</td>\n",
       "      <td>1.138917</td>\n",
       "      <td>20.414881</td>\n",
       "      <td>5.276077</td>\n",
       "      <td>-0.058847</td>\n",
       "      <td>-0.056868</td>\n",
       "      <td>-0.066306</td>\n",
       "      <td>-0.061562</td>\n",
       "      <td>-0.057827</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.066306</td>\n",
       "      <td>-0.066306</td>\n",
       "      <td>-0.066306</td>\n",
       "      <td>-0.066306</td>\n",
       "      <td>-0.066306</td>\n",
       "      <td>-0.066206</td>\n",
       "      <td>-0.066306</td>\n",
       "      <td>-0.066306</td>\n",
       "      <td>-0.066306</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.060642</td>\n",
       "      <td>3.539223</td>\n",
       "      <td>1.188689</td>\n",
       "      <td>20.349106</td>\n",
       "      <td>5.285100</td>\n",
       "      <td>-0.060945</td>\n",
       "      <td>-0.057627</td>\n",
       "      <td>-0.067051</td>\n",
       "      <td>-0.062269</td>\n",
       "      <td>-0.058559</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.067081</td>\n",
       "      <td>-0.067081</td>\n",
       "      <td>-0.067081</td>\n",
       "      <td>-0.067081</td>\n",
       "      <td>-0.067081</td>\n",
       "      <td>-0.066981</td>\n",
       "      <td>-0.067081</td>\n",
       "      <td>-0.067081</td>\n",
       "      <td>-0.067081</td>\n",
       "      <td>0.049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15686</th>\n",
       "      <td>0.060446</td>\n",
       "      <td>3.536152</td>\n",
       "      <td>0.978945</td>\n",
       "      <td>18.191447</td>\n",
       "      <td>10.543247</td>\n",
       "      <td>-0.067930</td>\n",
       "      <td>-0.054005</td>\n",
       "      <td>-0.073564</td>\n",
       "      <td>-0.067470</td>\n",
       "      <td>-0.053225</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073494</td>\n",
       "      <td>-0.073494</td>\n",
       "      <td>-0.073494</td>\n",
       "      <td>-0.073494</td>\n",
       "      <td>-0.073494</td>\n",
       "      <td>-0.073316</td>\n",
       "      <td>-0.073494</td>\n",
       "      <td>-0.073494</td>\n",
       "      <td>-0.073494</td>\n",
       "      <td>-0.135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15687</th>\n",
       "      <td>0.063511</td>\n",
       "      <td>2.357771</td>\n",
       "      <td>0.749811</td>\n",
       "      <td>18.294339</td>\n",
       "      <td>10.719576</td>\n",
       "      <td>-0.065421</td>\n",
       "      <td>-0.051665</td>\n",
       "      <td>-0.071069</td>\n",
       "      <td>-0.064957</td>\n",
       "      <td>-0.050471</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071016</td>\n",
       "      <td>-0.071016</td>\n",
       "      <td>-0.071016</td>\n",
       "      <td>-0.071016</td>\n",
       "      <td>-0.071016</td>\n",
       "      <td>-0.070837</td>\n",
       "      <td>-0.071016</td>\n",
       "      <td>-0.071016</td>\n",
       "      <td>-0.071016</td>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15688</th>\n",
       "      <td>0.064218</td>\n",
       "      <td>2.255666</td>\n",
       "      <td>0.790556</td>\n",
       "      <td>18.251030</td>\n",
       "      <td>10.812116</td>\n",
       "      <td>-0.065404</td>\n",
       "      <td>-0.051634</td>\n",
       "      <td>-0.070973</td>\n",
       "      <td>-0.064942</td>\n",
       "      <td>-0.050407</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.070991</td>\n",
       "      <td>-0.070991</td>\n",
       "      <td>-0.070991</td>\n",
       "      <td>-0.070991</td>\n",
       "      <td>-0.070991</td>\n",
       "      <td>-0.070813</td>\n",
       "      <td>-0.070991</td>\n",
       "      <td>-0.070991</td>\n",
       "      <td>-0.070991</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15689</th>\n",
       "      <td>0.063942</td>\n",
       "      <td>2.433615</td>\n",
       "      <td>0.869788</td>\n",
       "      <td>18.161534</td>\n",
       "      <td>10.915863</td>\n",
       "      <td>-0.066005</td>\n",
       "      <td>-0.051900</td>\n",
       "      <td>-0.071412</td>\n",
       "      <td>-0.065542</td>\n",
       "      <td>-0.050691</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071590</td>\n",
       "      <td>-0.071590</td>\n",
       "      <td>-0.071590</td>\n",
       "      <td>-0.071590</td>\n",
       "      <td>-0.071590</td>\n",
       "      <td>-0.071412</td>\n",
       "      <td>-0.071590</td>\n",
       "      <td>-0.071590</td>\n",
       "      <td>-0.071590</td>\n",
       "      <td>0.124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15690</th>\n",
       "      <td>0.062433</td>\n",
       "      <td>3.383307</td>\n",
       "      <td>1.141395</td>\n",
       "      <td>17.945449</td>\n",
       "      <td>10.987793</td>\n",
       "      <td>-0.068313</td>\n",
       "      <td>-0.054021</td>\n",
       "      <td>-0.073906</td>\n",
       "      <td>-0.067960</td>\n",
       "      <td>-0.052997</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073959</td>\n",
       "      <td>-0.073959</td>\n",
       "      <td>-0.073959</td>\n",
       "      <td>-0.073959</td>\n",
       "      <td>-0.073959</td>\n",
       "      <td>-0.073783</td>\n",
       "      <td>-0.073959</td>\n",
       "      <td>-0.073959</td>\n",
       "      <td>-0.073959</td>\n",
       "      <td>0.023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15691 rows × 460 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           의료기관      전입인구      전출인구        자가용    65세이상인구     재정자립도        지수  \\\n",
       "0      0.061995  3.233677  1.072803  20.468395   5.046401 -0.058389 -0.056174   \n",
       "1      0.064283  2.731338  0.949303  20.532285   5.114363 -0.057295 -0.055097   \n",
       "2      0.065673  2.507137  0.861445  20.552815   5.165028 -0.056776 -0.054713   \n",
       "3      0.061689  3.178491  1.138917  20.414881   5.276077 -0.058847 -0.056868   \n",
       "4      0.060642  3.539223  1.188689  20.349106   5.285100 -0.060945 -0.057627   \n",
       "...         ...       ...       ...        ...        ...       ...       ...   \n",
       "15686  0.060446  3.536152  0.978945  18.191447  10.543247 -0.067930 -0.054005   \n",
       "15687  0.063511  2.357771  0.749811  18.294339  10.719576 -0.065421 -0.051665   \n",
       "15688  0.064218  2.255666  0.790556  18.251030  10.812116 -0.065404 -0.051634   \n",
       "15689  0.063942  2.433615  0.869788  18.161534  10.915863 -0.066005 -0.051900   \n",
       "15690  0.062433  3.383307  1.141395  17.945449  10.987793 -0.068313 -0.054021   \n",
       "\n",
       "             변동       유치원    선행종합지수  ...  랜드마크_김포공항  랜드마크_남산타워  랜드마크_롯데월드  \\\n",
       "0     -0.065865 -0.061121 -0.057485  ...  -0.065896  -0.065896  -0.065896   \n",
       "1     -0.064843 -0.060031 -0.056349  ...  -0.064813  -0.064813  -0.064813   \n",
       "2     -0.064336 -0.059509 -0.055770  ...  -0.064285  -0.064285  -0.064285   \n",
       "3     -0.066306 -0.061562 -0.057827  ...  -0.066306  -0.066306  -0.066306   \n",
       "4     -0.067051 -0.062269 -0.058559  ...  -0.067081  -0.067081  -0.067081   \n",
       "...         ...       ...       ...  ...        ...        ...        ...   \n",
       "15686 -0.073564 -0.067470 -0.053225  ...  -0.073494  -0.073494  -0.073494   \n",
       "15687 -0.071069 -0.064957 -0.050471  ...  -0.071016  -0.071016  -0.071016   \n",
       "15688 -0.070973 -0.064942 -0.050407  ...  -0.070991  -0.070991  -0.070991   \n",
       "15689 -0.071412 -0.065542 -0.050691  ...  -0.071590  -0.071590  -0.071590   \n",
       "15690 -0.073906 -0.067960 -0.052997  ...  -0.073959  -0.073959  -0.073959   \n",
       "\n",
       "       랜드마크_서울월드컵경기장  랜드마크_야구장   랜드마크_없음  랜드마크_잠실야구장  랜드마크_코엑스  랜드마크_한강공원  \\\n",
       "0          -0.065896 -0.065896 -0.065794   -0.065896 -0.065896  -0.065896   \n",
       "1          -0.064813 -0.064813 -0.064711   -0.064813 -0.064813  -0.064813   \n",
       "2          -0.064285 -0.064285 -0.064183   -0.064285 -0.064285  -0.064285   \n",
       "3          -0.066306 -0.066306 -0.066206   -0.066306 -0.066306  -0.066306   \n",
       "4          -0.067081 -0.067081 -0.066981   -0.067081 -0.067081  -0.067081   \n",
       "...              ...       ...       ...         ...       ...        ...   \n",
       "15686      -0.073494 -0.073494 -0.073316   -0.073494 -0.073494  -0.073494   \n",
       "15687      -0.071016 -0.071016 -0.070837   -0.071016 -0.071016  -0.071016   \n",
       "15688      -0.070991 -0.070991 -0.070813   -0.070991 -0.070991  -0.070991   \n",
       "15689      -0.071590 -0.071590 -0.071412   -0.071590 -0.071590  -0.071590   \n",
       "15690      -0.073959 -0.073959 -0.073783   -0.073959 -0.073959  -0.073959   \n",
       "\n",
       "        상하강률  \n",
       "0      0.000  \n",
       "1      0.060  \n",
       "2     -0.047  \n",
       "3      0.002  \n",
       "4      0.049  \n",
       "...      ...  \n",
       "15686 -0.135  \n",
       "15687  0.035  \n",
       "15688  0.038  \n",
       "15689  0.124  \n",
       "15690  0.023  \n",
       "\n",
       "[15691 rows x 460 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,:-1] = df.iloc[:,:-1].apply(lambda x: (x - x.mean()) / x.std(), axis=1) \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모든 데이터 (15691, 459)\n",
      "training set (12552, 459) (12552, 1)\n",
      "test set (3139, 459) (3139, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data = df.drop(['상하강률'], axis=1)\n",
    "target_data = df[['상하강률']]\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_data, target_data, test_size=0.2)\n",
    "\n",
    "#x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.2) \n",
    "\n",
    "print('모든 데이터', train_data.shape)\n",
    "print('training set', x_train.shape, y_train.shape)\n",
    "#print('validation set', x_valid.shape, y_valid.shape)\n",
    "print('test set', x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbr = xgb.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "dtest = xgb.DMatrix(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_evaluate(max_depth, gamma, colsample_bytree, eta, min_child_weight, subsample):\n",
    "    params = {'eval_metric': 'rmse',\n",
    "              'max_depth': int(max_depth),\n",
    "              'subsample': float(subsample),\n",
    "              'eta': float(eta),\n",
    "              'gamma': gamma,\n",
    "              'colsample_bytree': colsample_bytree,\n",
    "              'min_child_weight' : int(min_child_weight)}\n",
    "    # Used around 1000 boosting rounds in the full model\n",
    "    cv_result = xgb.cv(params, dtrain, num_boost_round=100, nfold=3)    \n",
    "    \n",
    "    # Bayesian optimization only knows how to maximize, not minimize, so return the negative RMSE\n",
    "    return -1. * cv_result['test-rmse-mean'].iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... |    eta    |   gamma   | max_depth | min_ch... | subsample |\n",
      "-------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.2316  \u001b[0m | \u001b[0m 0.7667  \u001b[0m | \u001b[0m 0.07839 \u001b[0m | \u001b[0m 0.4422  \u001b[0m | \u001b[0m 3.019   \u001b[0m | \u001b[0m 5.639   \u001b[0m | \u001b[0m 0.6403  \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m-0.2288  \u001b[0m | \u001b[95m 0.7922  \u001b[0m | \u001b[95m 0.07248 \u001b[0m | \u001b[95m 0.178   \u001b[0m | \u001b[95m 2.063   \u001b[0m | \u001b[95m 3.551   \u001b[0m | \u001b[95m 0.6418  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.231   \u001b[0m | \u001b[0m 0.5633  \u001b[0m | \u001b[0m 0.08035 \u001b[0m | \u001b[0m 0.3074  \u001b[0m | \u001b[0m 3.187   \u001b[0m | \u001b[0m 5.515   \u001b[0m | \u001b[0m 0.6926  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.2328  \u001b[0m | \u001b[0m 0.3009  \u001b[0m | \u001b[0m 0.07883 \u001b[0m | \u001b[0m 0.929   \u001b[0m | \u001b[0m 4.913   \u001b[0m | \u001b[0m 3.008   \u001b[0m | \u001b[0m 0.6897  \u001b[0m |\n",
      "| \u001b[95m 5       \u001b[0m | \u001b[95m-0.2285  \u001b[0m | \u001b[95m 0.6549  \u001b[0m | \u001b[95m 0.06238 \u001b[0m | \u001b[95m 0.1076  \u001b[0m | \u001b[95m 2.001   \u001b[0m | \u001b[95m 3.01    \u001b[0m | \u001b[95m 0.7508  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-0.2294  \u001b[0m | \u001b[0m 0.317   \u001b[0m | \u001b[0m 0.08491 \u001b[0m | \u001b[0m 0.07525 \u001b[0m | \u001b[0m 2.046   \u001b[0m | \u001b[0m 3.085   \u001b[0m | \u001b[0m 0.6807  \u001b[0m |\n",
      "| \u001b[95m 7       \u001b[0m | \u001b[95m-0.2281  \u001b[0m | \u001b[95m 0.8203  \u001b[0m | \u001b[95m 0.06158 \u001b[0m | \u001b[95m 0.9999  \u001b[0m | \u001b[95m 2.011   \u001b[0m | \u001b[95m 3.015   \u001b[0m | \u001b[95m 0.7363  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.2293  \u001b[0m | \u001b[0m 0.897   \u001b[0m | \u001b[0m 0.0816  \u001b[0m | \u001b[0m 0.8626  \u001b[0m | \u001b[0m 2.01    \u001b[0m | \u001b[0m 3.03    \u001b[0m | \u001b[0m 0.7121  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.2291  \u001b[0m | \u001b[0m 0.554   \u001b[0m | \u001b[0m 0.08815 \u001b[0m | \u001b[0m 0.9917  \u001b[0m | \u001b[0m 2.001   \u001b[0m | \u001b[0m 3.155   \u001b[0m | \u001b[0m 0.6384  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.2301  \u001b[0m | \u001b[0m 0.6863  \u001b[0m | \u001b[0m 0.09862 \u001b[0m | \u001b[0m 0.02864 \u001b[0m | \u001b[0m 2.009   \u001b[0m | \u001b[0m 3.118   \u001b[0m | \u001b[0m 0.7303  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.2288  \u001b[0m | \u001b[0m 0.3819  \u001b[0m | \u001b[0m 0.08826 \u001b[0m | \u001b[0m 0.9702  \u001b[0m | \u001b[0m 2.024   \u001b[0m | \u001b[0m 5.793   \u001b[0m | \u001b[0m 0.6568  \u001b[0m |\n",
      "| \u001b[95m 12      \u001b[0m | \u001b[95m-0.2275  \u001b[0m | \u001b[95m 0.8231  \u001b[0m | \u001b[95m 0.05109 \u001b[0m | \u001b[95m 0.9304  \u001b[0m | \u001b[95m 2.019   \u001b[0m | \u001b[95m 5.841   \u001b[0m | \u001b[95m 0.7907  \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.2288  \u001b[0m | \u001b[0m 0.3053  \u001b[0m | \u001b[0m 0.08047 \u001b[0m | \u001b[0m 0.9868  \u001b[0m | \u001b[0m 2.017   \u001b[0m | \u001b[0m 5.851   \u001b[0m | \u001b[0m 0.6163  \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.2296  \u001b[0m | \u001b[0m 0.888   \u001b[0m | \u001b[0m 0.08991 \u001b[0m | \u001b[0m 0.8579  \u001b[0m | \u001b[0m 2.003   \u001b[0m | \u001b[0m 5.946   \u001b[0m | \u001b[0m 0.6737  \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.2284  \u001b[0m | \u001b[0m 0.3365  \u001b[0m | \u001b[0m 0.0621  \u001b[0m | \u001b[0m 0.9112  \u001b[0m | \u001b[0m 2.011   \u001b[0m | \u001b[0m 3.284   \u001b[0m | \u001b[0m 0.6437  \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.2282  \u001b[0m | \u001b[0m 0.3185  \u001b[0m | \u001b[0m 0.08223 \u001b[0m | \u001b[0m 0.9693  \u001b[0m | \u001b[0m 2.021   \u001b[0m | \u001b[0m 3.069   \u001b[0m | \u001b[0m 0.7172  \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.228   \u001b[0m | \u001b[0m 0.3553  \u001b[0m | \u001b[0m 0.06064 \u001b[0m | \u001b[0m 0.996   \u001b[0m | \u001b[0m 2.071   \u001b[0m | \u001b[0m 3.076   \u001b[0m | \u001b[0m 0.701   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.2276  \u001b[0m | \u001b[0m 0.8661  \u001b[0m | \u001b[0m 0.05872 \u001b[0m | \u001b[0m 0.9912  \u001b[0m | \u001b[0m 2.085   \u001b[0m | \u001b[0m 5.919   \u001b[0m | \u001b[0m 0.7868  \u001b[0m |\n",
      "=================================================================================================\n"
     ]
    }
   ],
   "source": [
    "xgb_bo = BayesianOptimization(xgb_evaluate, {'max_depth': (2, 5), \n",
    "                                             'gamma': (0, 1),\n",
    "                                             'colsample_bytree': (0.3, 0.9),\n",
    "                                              'eta' : (.05, .1),\n",
    "                                             'min_child_weight' : (3,6),\n",
    "                                             'subsample':(0.6, 0.8)})\n",
    "\n",
    "# Use the expected improvement acquisition function to handle negative numbers\n",
    "# Optimally needs quite a few more initiation points and number of iterations\n",
    "xgb_bo.maximize(init_points=3, n_iter=15, acq='ei')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best parameters\n",
    "params = xgb_bo.max['params']\n",
    "params['max_depth'] = int(params['max_depth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = xgb.train(params, dtrain, num_boost_round=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model3.predict(xgb.DMatrix(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(result)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error : 0.10205089667482185\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "print(\"Mean Absolute Error : \" + str(mean_absolute_error(result, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_squared_error : 0.039392054301084146\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "print(\"mean_squared_error : \" + str(mean_squared_error(result, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('머신러닝data.csv')\n",
    "df.head()\n",
    "\n",
    "df.iloc[:,:-1] = df.iloc[:,:-1].apply(lambda x: (x - x.mean()) / x.std(), axis=1) \n",
    "df\n",
    "\n",
    "import xgboost as xgb\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data = df.drop(['상하강률'], axis=1)\n",
    "target_data = df[['상하강률']]\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_data, target_data, test_size=0.2)\n",
    "\n",
    "#x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.2) \n",
    "\n",
    "print('모든 데이터', train_data.shape)\n",
    "print('training set', x_train.shape, y_train.shape)\n",
    "#print('validation set', x_valid.shape, y_valid.shape)\n",
    "print('test set', x_test.shape, y_test.shape)\n",
    "\n",
    "xgbr = xgb.XGBRegressor()\n",
    "\n",
    "dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "dtest = xgb.DMatrix(x_test)\n",
    "\n",
    "def xgb_evaluate(max_depth, gamma, colsample_bytree, eta, min_child_weight, subsample):\n",
    "    params = {'eval_metric': 'rmse',\n",
    "              'max_depth': int(max_depth),\n",
    "              'subsample': float(subsample),\n",
    "              'eta': float(eta),\n",
    "              'gamma': gamma,\n",
    "              'colsample_bytree': colsample_bytree,\n",
    "              'min_child_weight' : int(min_child_weight)}\n",
    "    # Used around 1000 boosting rounds in the full model\n",
    "    cv_result = xgb.cv(params, dtrain, num_boost_round=100, nfold=3)    \n",
    "    \n",
    "    # Bayesian optimization only knows how to maximize, not minimize, so return the negative RMSE\n",
    "    return -1. * cv_result['test-rmse-mean'].iloc[-1]\n",
    "\n",
    "xgb_bo = BayesianOptimization(xgb_evaluate, {'max_depth': (2, 5), \n",
    "                                             'gamma': (0, 1),\n",
    "                                             'colsample_bytree': (0.3, 0.9),\n",
    "                                              'eta' : (.05, .1),\n",
    "                                             'min_child_weight' : (3,6),\n",
    "                                             'subsample':(0.6, 0.8)})\n",
    "\n",
    "# Use the expected improvement acquisition function to handle negative numbers\n",
    "# Optimally needs quite a few more initiation points and number of iterations\n",
    "xgb_bo.maximize(init_points=3, n_iter=15, acq='ei')\n",
    "\n",
    "# best parameters\n",
    "params = xgb_bo.max['params']\n",
    "params['max_depth'] = int(params['max_depth'])\n",
    "\n",
    "model3 = xgb.train(params, dtrain, num_boost_round=100)\n",
    "\n",
    "result = model3.predict(xgb.DMatrix(x_test))\n",
    "\n",
    "plt.plot(result)\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print(\"Mean Absolute Error : \" + str(mean_absolute_error(result, y_test)))\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(\"mean_squared_error : \" + str(mean_squared_error(result, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>의료기관</th>\n",
       "      <th>전입인구</th>\n",
       "      <th>전출인구</th>\n",
       "      <th>자가용</th>\n",
       "      <th>65세이상인구</th>\n",
       "      <th>재정자립도</th>\n",
       "      <th>지수</th>\n",
       "      <th>변동</th>\n",
       "      <th>유치원</th>\n",
       "      <th>선행종합지수</th>\n",
       "      <th>...</th>\n",
       "      <th>랜드마크_고속버스터미널</th>\n",
       "      <th>랜드마크_김포공항</th>\n",
       "      <th>랜드마크_남산타워</th>\n",
       "      <th>랜드마크_롯데월드</th>\n",
       "      <th>랜드마크_서울월드컵경기장</th>\n",
       "      <th>랜드마크_야구장</th>\n",
       "      <th>랜드마크_없음</th>\n",
       "      <th>랜드마크_잠실야구장</th>\n",
       "      <th>랜드마크_코엑스</th>\n",
       "      <th>랜드마크_한강공원</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8861</th>\n",
       "      <td>0.082297</td>\n",
       "      <td>2.699717</td>\n",
       "      <td>1.001343</td>\n",
       "      <td>19.397215</td>\n",
       "      <td>8.440793</td>\n",
       "      <td>-0.061130</td>\n",
       "      <td>-0.053471</td>\n",
       "      <td>-0.069726</td>\n",
       "      <td>-0.064333</td>\n",
       "      <td>-0.052385</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069763</td>\n",
       "      <td>-0.069763</td>\n",
       "      <td>-0.069763</td>\n",
       "      <td>-0.069763</td>\n",
       "      <td>-0.069763</td>\n",
       "      <td>-0.069763</td>\n",
       "      <td>-0.069576</td>\n",
       "      <td>-0.069763</td>\n",
       "      <td>-0.069763</td>\n",
       "      <td>-0.069763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10569</th>\n",
       "      <td>0.050264</td>\n",
       "      <td>2.851315</td>\n",
       "      <td>0.989891</td>\n",
       "      <td>20.171152</td>\n",
       "      <td>6.322819</td>\n",
       "      <td>-0.060083</td>\n",
       "      <td>-0.050953</td>\n",
       "      <td>-0.067031</td>\n",
       "      <td>-0.061487</td>\n",
       "      <td>-0.052685</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.067031</td>\n",
       "      <td>-0.067031</td>\n",
       "      <td>-0.067031</td>\n",
       "      <td>-0.067031</td>\n",
       "      <td>-0.067031</td>\n",
       "      <td>-0.067031</td>\n",
       "      <td>-0.066858</td>\n",
       "      <td>-0.067031</td>\n",
       "      <td>-0.067031</td>\n",
       "      <td>-0.067031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12490</th>\n",
       "      <td>0.095010</td>\n",
       "      <td>2.235437</td>\n",
       "      <td>0.816425</td>\n",
       "      <td>18.357204</td>\n",
       "      <td>10.633179</td>\n",
       "      <td>-0.064957</td>\n",
       "      <td>-0.051513</td>\n",
       "      <td>-0.070871</td>\n",
       "      <td>-0.064452</td>\n",
       "      <td>-0.049818</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.070911</td>\n",
       "      <td>-0.070911</td>\n",
       "      <td>-0.070911</td>\n",
       "      <td>-0.070911</td>\n",
       "      <td>-0.070911</td>\n",
       "      <td>-0.070911</td>\n",
       "      <td>-0.070709</td>\n",
       "      <td>-0.070911</td>\n",
       "      <td>-0.070911</td>\n",
       "      <td>-0.070911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8427</th>\n",
       "      <td>0.070836</td>\n",
       "      <td>1.962476</td>\n",
       "      <td>0.708300</td>\n",
       "      <td>19.928558</td>\n",
       "      <td>7.382730</td>\n",
       "      <td>-0.059748</td>\n",
       "      <td>-0.052797</td>\n",
       "      <td>-0.066263</td>\n",
       "      <td>-0.060197</td>\n",
       "      <td>-0.051331</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.066292</td>\n",
       "      <td>-0.066292</td>\n",
       "      <td>-0.066292</td>\n",
       "      <td>-0.066292</td>\n",
       "      <td>-0.066292</td>\n",
       "      <td>-0.066292</td>\n",
       "      <td>-0.066147</td>\n",
       "      <td>-0.066292</td>\n",
       "      <td>-0.066292</td>\n",
       "      <td>-0.066292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10972</th>\n",
       "      <td>0.069413</td>\n",
       "      <td>2.577209</td>\n",
       "      <td>0.806236</td>\n",
       "      <td>16.199114</td>\n",
       "      <td>13.632690</td>\n",
       "      <td>-0.067932</td>\n",
       "      <td>-0.048549</td>\n",
       "      <td>-0.073392</td>\n",
       "      <td>-0.068683</td>\n",
       "      <td>-0.046729</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073461</td>\n",
       "      <td>-0.073461</td>\n",
       "      <td>-0.073461</td>\n",
       "      <td>-0.073461</td>\n",
       "      <td>-0.073461</td>\n",
       "      <td>-0.073461</td>\n",
       "      <td>-0.073233</td>\n",
       "      <td>-0.073461</td>\n",
       "      <td>-0.073461</td>\n",
       "      <td>-0.073461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6111</th>\n",
       "      <td>0.070118</td>\n",
       "      <td>2.181587</td>\n",
       "      <td>0.757805</td>\n",
       "      <td>16.799499</td>\n",
       "      <td>12.964229</td>\n",
       "      <td>-0.066446</td>\n",
       "      <td>-0.049144</td>\n",
       "      <td>-0.072260</td>\n",
       "      <td>-0.067002</td>\n",
       "      <td>-0.046480</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.072329</td>\n",
       "      <td>-0.072329</td>\n",
       "      <td>-0.072329</td>\n",
       "      <td>-0.072329</td>\n",
       "      <td>-0.072329</td>\n",
       "      <td>-0.072329</td>\n",
       "      <td>-0.072098</td>\n",
       "      <td>-0.072329</td>\n",
       "      <td>-0.072329</td>\n",
       "      <td>-0.072329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10828</th>\n",
       "      <td>0.054072</td>\n",
       "      <td>2.303476</td>\n",
       "      <td>0.859112</td>\n",
       "      <td>19.522444</td>\n",
       "      <td>8.288883</td>\n",
       "      <td>-0.058098</td>\n",
       "      <td>-0.048427</td>\n",
       "      <td>-0.068484</td>\n",
       "      <td>-0.061560</td>\n",
       "      <td>-0.046419</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068484</td>\n",
       "      <td>-0.068484</td>\n",
       "      <td>-0.068484</td>\n",
       "      <td>-0.068484</td>\n",
       "      <td>-0.068484</td>\n",
       "      <td>-0.068484</td>\n",
       "      <td>-0.068253</td>\n",
       "      <td>-0.068484</td>\n",
       "      <td>-0.068484</td>\n",
       "      <td>-0.068484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4910</th>\n",
       "      <td>0.112554</td>\n",
       "      <td>2.916029</td>\n",
       "      <td>0.859290</td>\n",
       "      <td>20.524679</td>\n",
       "      <td>5.056684</td>\n",
       "      <td>-0.054465</td>\n",
       "      <td>-0.053186</td>\n",
       "      <td>-0.065036</td>\n",
       "      <td>-0.062025</td>\n",
       "      <td>-0.053793</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.064997</td>\n",
       "      <td>-0.064997</td>\n",
       "      <td>-0.064997</td>\n",
       "      <td>-0.064997</td>\n",
       "      <td>-0.064997</td>\n",
       "      <td>-0.064997</td>\n",
       "      <td>-0.064868</td>\n",
       "      <td>-0.064997</td>\n",
       "      <td>-0.064997</td>\n",
       "      <td>-0.064997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5443</th>\n",
       "      <td>0.067557</td>\n",
       "      <td>2.705581</td>\n",
       "      <td>0.944688</td>\n",
       "      <td>18.507641</td>\n",
       "      <td>10.243379</td>\n",
       "      <td>-0.061259</td>\n",
       "      <td>-0.048612</td>\n",
       "      <td>-0.071713</td>\n",
       "      <td>-0.065288</td>\n",
       "      <td>-0.049300</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071662</td>\n",
       "      <td>-0.071662</td>\n",
       "      <td>-0.071662</td>\n",
       "      <td>-0.071662</td>\n",
       "      <td>-0.071662</td>\n",
       "      <td>-0.071662</td>\n",
       "      <td>-0.071407</td>\n",
       "      <td>-0.071662</td>\n",
       "      <td>-0.071662</td>\n",
       "      <td>-0.071662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>0.087498</td>\n",
       "      <td>3.185329</td>\n",
       "      <td>1.123773</td>\n",
       "      <td>19.782312</td>\n",
       "      <td>7.284353</td>\n",
       "      <td>-0.059927</td>\n",
       "      <td>-0.048263</td>\n",
       "      <td>-0.069442</td>\n",
       "      <td>-0.060039</td>\n",
       "      <td>-0.050255</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069442</td>\n",
       "      <td>-0.069442</td>\n",
       "      <td>-0.069442</td>\n",
       "      <td>-0.069442</td>\n",
       "      <td>-0.069442</td>\n",
       "      <td>-0.069442</td>\n",
       "      <td>-0.069218</td>\n",
       "      <td>-0.069442</td>\n",
       "      <td>-0.069442</td>\n",
       "      <td>-0.069442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3139 rows × 459 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           의료기관      전입인구      전출인구        자가용    65세이상인구     재정자립도        지수  \\\n",
       "8861   0.082297  2.699717  1.001343  19.397215   8.440793 -0.061130 -0.053471   \n",
       "10569  0.050264  2.851315  0.989891  20.171152   6.322819 -0.060083 -0.050953   \n",
       "12490  0.095010  2.235437  0.816425  18.357204  10.633179 -0.064957 -0.051513   \n",
       "8427   0.070836  1.962476  0.708300  19.928558   7.382730 -0.059748 -0.052797   \n",
       "10972  0.069413  2.577209  0.806236  16.199114  13.632690 -0.067932 -0.048549   \n",
       "...         ...       ...       ...        ...        ...       ...       ...   \n",
       "6111   0.070118  2.181587  0.757805  16.799499  12.964229 -0.066446 -0.049144   \n",
       "10828  0.054072  2.303476  0.859112  19.522444   8.288883 -0.058098 -0.048427   \n",
       "4910   0.112554  2.916029  0.859290  20.524679   5.056684 -0.054465 -0.053186   \n",
       "5443   0.067557  2.705581  0.944688  18.507641  10.243379 -0.061259 -0.048612   \n",
       "1396   0.087498  3.185329  1.123773  19.782312   7.284353 -0.059927 -0.048263   \n",
       "\n",
       "             변동       유치원    선행종합지수  ...  랜드마크_고속버스터미널  랜드마크_김포공항  랜드마크_남산타워  \\\n",
       "8861  -0.069726 -0.064333 -0.052385  ...     -0.069763  -0.069763  -0.069763   \n",
       "10569 -0.067031 -0.061487 -0.052685  ...     -0.067031  -0.067031  -0.067031   \n",
       "12490 -0.070871 -0.064452 -0.049818  ...     -0.070911  -0.070911  -0.070911   \n",
       "8427  -0.066263 -0.060197 -0.051331  ...     -0.066292  -0.066292  -0.066292   \n",
       "10972 -0.073392 -0.068683 -0.046729  ...     -0.073461  -0.073461  -0.073461   \n",
       "...         ...       ...       ...  ...           ...        ...        ...   \n",
       "6111  -0.072260 -0.067002 -0.046480  ...     -0.072329  -0.072329  -0.072329   \n",
       "10828 -0.068484 -0.061560 -0.046419  ...     -0.068484  -0.068484  -0.068484   \n",
       "4910  -0.065036 -0.062025 -0.053793  ...     -0.064997  -0.064997  -0.064997   \n",
       "5443  -0.071713 -0.065288 -0.049300  ...     -0.071662  -0.071662  -0.071662   \n",
       "1396  -0.069442 -0.060039 -0.050255  ...     -0.069442  -0.069442  -0.069442   \n",
       "\n",
       "       랜드마크_롯데월드  랜드마크_서울월드컵경기장  랜드마크_야구장   랜드마크_없음  랜드마크_잠실야구장  랜드마크_코엑스  \\\n",
       "8861   -0.069763      -0.069763 -0.069763 -0.069576   -0.069763 -0.069763   \n",
       "10569  -0.067031      -0.067031 -0.067031 -0.066858   -0.067031 -0.067031   \n",
       "12490  -0.070911      -0.070911 -0.070911 -0.070709   -0.070911 -0.070911   \n",
       "8427   -0.066292      -0.066292 -0.066292 -0.066147   -0.066292 -0.066292   \n",
       "10972  -0.073461      -0.073461 -0.073461 -0.073233   -0.073461 -0.073461   \n",
       "...          ...            ...       ...       ...         ...       ...   \n",
       "6111   -0.072329      -0.072329 -0.072329 -0.072098   -0.072329 -0.072329   \n",
       "10828  -0.068484      -0.068484 -0.068484 -0.068253   -0.068484 -0.068484   \n",
       "4910   -0.064997      -0.064997 -0.064997 -0.064868   -0.064997 -0.064997   \n",
       "5443   -0.071662      -0.071662 -0.071662 -0.071407   -0.071662 -0.071662   \n",
       "1396   -0.069442      -0.069442 -0.069442 -0.069218   -0.069442 -0.069442   \n",
       "\n",
       "       랜드마크_한강공원  \n",
       "8861   -0.069763  \n",
       "10569  -0.067031  \n",
       "12490  -0.070911  \n",
       "8427   -0.066292  \n",
       "10972  -0.073461  \n",
       "...          ...  \n",
       "6111   -0.072329  \n",
       "10828  -0.068484  \n",
       "4910   -0.064997  \n",
       "5443   -0.071662  \n",
       "1396   -0.069442  \n",
       "\n",
       "[3139 rows x 459 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 지섭이형 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Downloading lightgbm-2.3.1-py2.py3-none-win_amd64.whl (544 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from lightgbm) (1.18.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\anaconda3\\lib\\site-packages (from lightgbm) (0.22.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\user\\anaconda3\\lib\\site-packages (from lightgbm) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn->lightgbm) (0.14.1)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-2.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ 추가한 모델 ##################\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (1.18.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\user\\anaconda3\\lib\\site-packages (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scipy) (1.18.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy \n",
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-0.23.1-cp37-cp37m-win_amd64.whl (6.8 MB)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn) (1.18.1)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn) (0.14.1)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: threadpoolctl, scikit-learn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.22.1\n",
      "    Uninstalling scikit-learn-0.22.1:\n",
      "      Successfully uninstalled scikit-learn-0.22.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an EnvironmentError: [WinError 5] 액세스가 거부되었습니다: 'c:\\\\users\\\\user\\\\anaconda3\\\\lib\\\\site-packages\\\\~klearn\\\\decomposition\\\\_cdnmf_fast.cp37-win_amd64.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[443 493 455 ... 611 342 406]\n",
      "continuous\n",
      "multiclass\n",
      "multiclass\n",
      "[344 559 335 ... 356 336 323]\n",
      "continuous\n",
      "multiclass\n",
      "multiclass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "training_scores_encoded = lab_enc.fit_transform(y_train)\n",
    "print(training_scores_encoded)\n",
    "print(utils.multiclass.type_of_target(y_train))\n",
    "print(utils.multiclass.type_of_target(y_train.astype('int')))\n",
    "print(utils.multiclass.type_of_target(training_scores_encoded))\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "test_scores_encoded = lab_enc.fit_transform(y_test)\n",
    "print(test_scores_encoded)\n",
    "print(utils.multiclass.type_of_target(y_test))\n",
    "print(utils.multiclass.type_of_target(y_test.astype('int')))\n",
    "print(utils.multiclass.type_of_target(test_scores_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/8 [00:00<?, ?it/s]C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:672: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      " 12%|██████████▌                                                                         | 1/8 [00:56<06:34, 56.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsRegressor                                 -1.624119 56.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:672: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      " 25%|████████████████████▎                                                            | 2/8 [39:56<1:14:09, 741.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor                                        -1.642732 2340.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:672: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n",
    "\n",
    "clfs = [\n",
    "   (\n",
    "        KNeighborsRegressor(),              # 사용하려는 모델\n",
    "        {'n_neighbors': [3,5,7,9,11],        # 최적화하려는 하이퍼파라미터\n",
    "         'weights': ['uniform','distance']}\n",
    "    ),\n",
    "    (\n",
    "        MLPRegressor(random_state=0),\n",
    "        {'batch_size': [32, 64, 128],\n",
    "         'learning_rate' : ['constant', 'adaptive'],\n",
    "         'activation': ['tanh', 'relu'],\n",
    "         'solver': ['sgd', 'adam']}\n",
    "    ),\n",
    "    (\n",
    "        RandomForestRegressor(random_state=0),\n",
    "        {'n_estimators': [100,200,300],\n",
    "         'max_depth': [3,4,5,6,7,8,9]}\n",
    "        # 'max_features': (np.arange(0.5, 1.0, 0.1)*x_train.shape[1]).astype(int)}\n",
    "    ),\n",
    "    (\n",
    "        GradientBoostingRegressor(random_state=0),\n",
    "        {'n_estimators': [100, 200, 300],\n",
    "         'learning_rate': [1, 0.1, 0.01]}\n",
    "        # 'max_features': (np.arange(0.5, 1.0, 0.1)*x_train.shape[1]).astype(int)}\n",
    "    ),\n",
    "    (\n",
    "        XGBRegressor(tree_method = 'hist', random_state=0),\n",
    "        {'min_child_weight': range(0, 121, 20),\n",
    "         'learning_rate': np.arange(0.1, 0.6, 0.1),\n",
    "         'subsample': np.arange(0.5, 1.0, 0.1)}\n",
    "    ),\n",
    "    (\n",
    "        LGBMRegressor(random_state=0),\n",
    "        {'min_child_weight': range(0, 121, 20),\n",
    "         'learning_rate': np.arange(0.1, 0.6, 0.1),\n",
    "         'subsample': np.arange(0.5, 1.0, 0.1)}\n",
    "    ),\n",
    "      (\n",
    "        AdaBoostRegressor(random_state = 777),\n",
    "        {'n_estimators' : [100,200,300],\n",
    "         'learning_rate' : [0.5, 0.6, 0.7, 0.8, 0.9, 1.0]}\n",
    "    ),\n",
    "    (\n",
    "        ExtraTreesRegressor(random_state=0),\n",
    "        {'n_estimators': range(50, 200, 10),\n",
    "         'max_depth': range(2, 15)} #엑스트라트리 모델 추가\n",
    "    )\n",
    "]\n",
    "\n",
    "clfs_tuned = []  # 튜닝된 모델을 저장\n",
    "\n",
    "############## cv 변경함 ###################\n",
    "sscv = StratifiedKFold(n_splits = 5,shuffle = True, random_state = 0)\n",
    "\n",
    "for clf, param_grid in tqdm(clfs):\n",
    "    start = time.time()\n",
    "    rand_search = GridSearchCV(clf, param_grid, \n",
    "                                     cv=sscv, n_jobs=-1)\n",
    "    rand_search.fit(x_train, training_scores_encoded)\n",
    "    clf_name = type(clf).__name__\n",
    "    clf_score = rand_search.score(x_test, test_scores_encoded)\n",
    "    print('{:30s} {:30f} {:.1f}'.format(clf_name, clf_score, time.time() - start))\n",
    "    clfs_tuned.append((clf_name, rand_search, clf_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = [\n",
    "    'KNeighborsClassifier', \n",
    "    'MLPClassifier',\n",
    "    'LogisticRegression', \n",
    "    'RandomForestClassifier', \n",
    "    'GradientBoostingClassifier',    \n",
    "    'XGBClassifier',\n",
    "    'LGBMClassifier',\n",
    "    'Support Vector Machine',\n",
    "    'AdaBoostClassifier',\n",
    "    'ExtraTreesClassifier'\n",
    "]\n",
    "models_for_ensemble = [clf for clf in clfs_tuned if clf[0] in selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from scipy.stats.mstats import gmean\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "max_score = 0\n",
    "for p in tqdm([0, 1,2.56]):  # p==1:산술평균, p=0:기하평균, 그 외:멱평균(주의:멱평균은 과적합 가능성이 높음)    \n",
    "    for i in range(2, len(models_for_ensemble)+1):\n",
    "        for models in combinations(models_for_ensemble, i):\n",
    "            if p == 0:\n",
    "                pred_mean = gmean([clf.predict_proba(X_valid)[:,1] for name, clf, _ in models], axis=0)\n",
    "            else:\n",
    "                preds = [clf.predict_proba(X_valid)[:,1] for name, clf, _ in models]\n",
    "                pred_mean = (np.sum(np.array(preds)**p, axis=0) / len(models))**(1/p)\n",
    "            score = roc_auc_score(y_valid, pred_mean)\n",
    "            if max_score < score:\n",
    "                best_avg_ensemble = (p, models, score)\n",
    "                max_score = score\n",
    "\n",
    "p, models, score = best_avg_ensemble\n",
    "print('p={}\\n{}\\n{}'.format(p, '●'.join([clf_name for clf_name, _, _ in models]), score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vecstack import StackingTransformer\n",
    "\n",
    "# Initialize 1st level estimators\n",
    "# 사용하지 않을 모델은 주석 처리하세요.\n",
    "selected = [\n",
    "    'KNeighborsClassifier', \n",
    "    'MLPClassifier',\n",
    "    'LogisticRegression', \n",
    "    'RandomForestClassifier', \n",
    "    'GradientBoostingClassifier',    \n",
    "    'XGBClassifier',\n",
    "    'LGBMClassifier',\n",
    "    'Support Vector Machine',\n",
    "    'AdaBoostClassifier',\n",
    "    'ExtraTreesClassifier'\n",
    "]\n",
    "estimators = [(name, clf) for name, clf, _ in clfs_tuned if name in selected]\n",
    "              \n",
    "# Initialize StackingTransformer\n",
    "stack = StackingTransformer(estimators, regression=False, needs_proba=True, metric=None,\n",
    "                            n_folds=5, stratified=True, shuffle=True, random_state=0)\n",
    "\n",
    "# Fit\n",
    "stack = stack.fit(X_train, y_train)\n",
    "\n",
    "# Get your stacked features\n",
    "S_train = stack.transform(X_train)\n",
    "S_valid = stack.transform(X_valid)\n",
    "S_test = stack.transform(X_test_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for final ensemble\n",
    "df1_s_train = S_train.copy()\n",
    "df1_s_valid = S_valid.copy()\n",
    "df1_s_test = S_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lgbm meta model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbounds = { 'learning_rate': (0.01, 1.5),\n",
    "            'n_estimators': (50, 250),\n",
    "            'max_depth': (3,10),   \n",
    "            'subsample': (0.8,0.95), \n",
    "            'colsample_bytree': (0.75,0.9),   \n",
    "            'num_leaves': (2,10),\n",
    "            'min_child_weight': (1, 7)}\n",
    "\n",
    "\n",
    "def meta_opt(learning_rate, n_estimators, max_depth, subsample, colsample_bytree, num_leaves, min_child_weight):\n",
    "\n",
    "    params = {\n",
    "        'learning_rate': learning_rate,\n",
    "        'n_estimators' : int(round(n_estimators)),\n",
    "        'max_depth' : int(round(max_depth)),\n",
    "        'subsample': subsample,\n",
    "        'colsample_bytree' : colsample_bytree,\n",
    "        'num_leaves' : int(round(num_leaves)),\n",
    "        'min_child_weight' : min_child_weight,\n",
    "        'n_jobs' : -1\n",
    "    }\n",
    "    \n",
    "    meta_model = LGBMClassifier(**params)\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=4 , shuffle=True, random_state=1)\n",
    "\n",
    "    score = cross_val_score(meta_model, df1_s_train, y_train, scoring='roc_auc', cv=skf, n_jobs=-1)\n",
    "    \n",
    "    return np.mean(score)\n",
    "\n",
    "BO_meta = BayesianOptimization(f = meta_opt, pbounds = pbounds, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BO_meta.maximize(init_points=50, n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BO_rf.res  # 모든 성능 들어가있음\n",
    "BO_meta.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_params = BO_meta.max['params']\n",
    "\n",
    "max_params['n_estimators'] = int(round(max_params['n_estimators']))\n",
    "max_params['max_depth'] = int(round(max_params['max_depth']))\n",
    "max_params['num_leaves'] = int(round(max_params['num_leaves']))\n",
    "\n",
    "max_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_clf = LGBMClassifier(**max_params)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=4 , shuffle=True, random_state=1)\n",
    "\n",
    "scores = cross_val_score(meta_clf, X_train, y_train, scoring='roc_auc', cv=skf, n_jobs=-1)\n",
    "\n",
    "print(scores)\n",
    "print(f'최대성능: {max(scores)}\\n평균성능: {np.mean(scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_clf.fit(df1_s_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
